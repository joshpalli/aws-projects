# Generating a Serverless Data Lake
This data engineering project is a deep dive into data ingestion, ETL, and analytics services on AWS. In this project, I created a data set with Amazon Kinesis Data Firehose, using real-time data generating and streaming to build a data lake. From there, I used AWS Glue Crawlers to automatically construct a schema for my data lake and catalog my data. I then launched an ETL job on AWS Glue for my data to be extracted from files stored in S3, transformed into an Apache Parquet format, and then loaded onto a separate folder on my S3 bucket.
